寄存器--一级缓存-二级缓存-三级缓存-内存-硬盘

将不常用数据放到内存中。

最早的内存技术

- 覆盖技术：在较小的内存运行较大的程序。将程序按模块分开。
- 交换技术 ：将暂时不能运行的程序送到外存。

操作系统把一个进程的整个地址保存到外存，而将外存中的某个进程的地址空间读入内存。

硬盘中需要一个交换区（swap）。交换区足够大，将存放所有用户进程的所有内存映射的拷贝。

### 虚拟内存技术

在内存不够用的情况，使用覆盖、交换技术

物理内存+硬盘=虚拟内存

程序的局部性原理：程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作地址，分别局限在一定范围。

- 时间局部性
- 空间局部性

可以在页式或段式内存管理的基础上实现

- 在装入内存时，不必将全部内存装入内存，而只需要将当前执行的部分页面放入内存
- 在程序执行过程中，如果需要执行的指令或访问的数据尚未存在，则由处理器通知操作系统将相应的页面调入内存
- 操作系统将内存暂时不适用的页面保存到外存

**虚拟技术特征**

- 大的用户空间。通过物理内存和外存相结合
- 部分交换，交换对应的段或者页。交换粒度小
- 不连续性：物理内存不连续，虚拟地址空间使用的不连续

 内存管理算法都是基于一个基本要求：执行指令必须在物理内存中，满足这一要求的第一种方法是整个进程放在内存中。动态载入能帮助减轻这一限制，但是它需要程序员特别小心地做一些额外的工作。

指令必须都在物理内存内的这一限制，似乎是必须和合理的，但也是不幸的，因为这使得程序的大小被限制在物理内存的大小内。事实上，研究实际程序会发现，许多情况下并不需要将整个程序放到内存中。即使在需要完整程序的时候，也并不是同时需要所有的程序。

因此运行一个部分在内存中的程序不仅有利于系统，还有利于用户。



**虚拟内存（virtual memory）**将用户逻辑内存和物理内存分开。这在现有物理内存有限的情况下，为程序员提供了巨大的虚拟内存。 

![虚拟地址空间](http://img.blog.csdn.net/20151209092437491) 

进程的虚拟地址空间就是进程如何在内存中存放的逻辑（或虚拟）视图。通常，该视图为进程从某一个逻辑地址（如地址0）开始，连续存放。 

![虚拟地址空间](http://img.blog.csdn.net/20151209092641518) 

物理地址可以按页幁来组织，且分配给进程的物理页帧也可能不是连续的。这就需要

内存管理单元（MMU）将逻辑页映射到内存的物理页帧。 

如上图显示，运行随着动态内存的分配，堆可向上生长。类似地，还允许随着子程序的不断调用，栈可以向下生长。堆与栈之间的巨大空白空间(或hole)为虚拟地址的一部分，只有在堆与栈生长的时候，才需要实际的物理页。

包括空白的虚拟地址空间成为稀地址空间

，采用稀地址空间的优点是：随着程序的执行，栈或者堆段的生长或需要载入动态链接库（或共享对象）时，这些空白可以填充。

除了将逻辑内存与物理内存分开，虚拟内存也允许文件和内存通过共享页而为两个或者多个进程所共享，这样带来了如下的有点：

- **通过将共享对象映射到虚拟地址空间，系统库可为多个进程所共享。**虽然每个进程都认为共享库是其虚拟地址空间的一部分，而共享库所用的物理内存的实际页是为所有进程所共享。通常，库是按制度方式来链接每个进程的空间的。
- **类似的，虚拟内存允许进程共享内存。**两个或者多个进程之间可以通过使用共享内存来相互通信。虚拟内存允许一个进程创建内存区域，以便与其他进程进行共享。共享该内存区域的进程认为它是其虚拟地址空间的一部分，而事实上这部分是共享的。

![虚拟地址空间](http://img.blog.csdn.net/20151209094133265) 

- 虚拟内存可允许在用系统调用fork()创建进程期间共享页，从而加快进程的创建。

## **按需调页**

一个执行程序从磁盘载入内存的时候有两种方法。 
\1. 选择在程序执行时，将整个程序载入到内存中。不过这种方法的问题是可能开始并不需要整个程序在内存中。如有的程序开始时带有一组用户可选的选项。载入整个程序，也就将所有选项的执行代码都载入到内存中，而不管这些选项是否使用。 
\2. 另一种选择是在需要时才调入相应的页。这种技术称为**按需调页(demand paging)**，常为虚拟内存系统所采用。

按需调页系统看类似于使用交换的分页系统，进程驻留在第二级存储器上（通常为磁盘）。当需要执行进程时，将它换入内存。不过，不是讲整个进程换入内存，而是使用懒惰交换(lazy swapper)。懒惰交换只有在需要页时，才将它调入内存。由于将进程看做是一系列的页，而不是一个大的连续空间，因此使用**交换**从技术上来讲并不正确。交换程序(swapper)对整个进程进行操作，而调页程序(pager)只是对进程的单个页进行操作。因此， 在讨论有关按需调页时，需要使用**调页程序**而不是**交换程序**。 

![虚拟地址空间](http://img.blog.csdn.net/20151216093906358) 

### **基本概念**

当换入进程时，调页程序推测在该进程再次换出之前使用到的哪些页，仅仅把需要的页调入内存。从而减少交换时间和所需的物理内存空间。

这种方案需要硬件支持区分哪些页在内存，哪些在磁盘。采用有效/无效位来表示。当页表中，一个条目的该位为有效时，表示该页合法且在内存中；反之，可能非法，也可能合法但不在内存中。 

![这里写图片描述](http://img.my.csdn.net/uploads/201212/14/1355499284_6420.jpg)

如果进程从不试图访问标记为无效的页，那么并没有什么影响，因此，如果推测正确且只调入所有真正需要的页，那么进程就可如同所有页都调入内存一样正常运行。

当进程试图访问这些尚未调入内存的页时，会引起**页错误陷阱（page-fault trap）**。这种情况的处理方式如下：

- 1）检查进程的内部页表（通常与PCB一起保存）。以确定该引用是的合法还是非法的地址访问。
- 2）如果非法，则终止进程；如果引用有效但是尚未调入页面，则现在进行调入。
- 3）找到一个空闲帧（如，从空闲帧表中选取一个）。
- 4）调度一个磁盘操作，以便将所需页调入刚分配的帧
- 5）磁盘读操作完成后，修改进程的内部表和页表，表示该页已在内存中。
- 6）重新开始因陷阱而中断的指令。

![这里写图片描述](http://img.blog.csdn.net/20151216170553626)

例如，block move 问题。 

![这里写图片描述](http://img.blog.csdn.net/20151216171135773)

MVC指令能够移动256B。

- 块可能跨越页边界
- 移动部分字符后出现页错误
- 如果源和目的块有重叠
- 源块可能已经被修改

解决方案： 
\- 试图存取两个块的两端 
\- 使用临时寄存器保存被覆盖位置的值

### **按需调页的性能**

按需调页对计算机系统的性能有重要影响，下面计算一下关于按需调页内存的有效访问时间（effective access time）。

设p(0≤p≤1)为页错误的概率，ma为内存访问时间: 

有效访问时间=(1−p)×ma+p×页错误时间

如果p→0，则不存在页错误；

如果p→1，则每次访问都存在页错误，即**纯粹按需调页(pure demand paging)**。

其中页错误时间有很多，主要是下面三种：

- 处理页错误中断
- 读入页（页换入时间）
- 重新启动进程

### **按需调页的例子**

内存存取时间 =200 ns 
平均页错误服务时间 =8 ms

EAT=(1−p)×200 ns+p(8 ms)200+p×7999800

如果每次1000次访问中有1次页错误，则EAT=8.2ns。即，因按需调页而慢40倍，如果需要性能降低不超过10%，则需要

p<0.0000025

因此来看，对于按需调页，降低页错误率至关重要。

另外是对交换空间的处理的使用。磁盘IO到交换空间通常比到文件系统要快，因为交换空间是按大块进行分配，并不使用文件查找和间接分配方法。因此，在进程开始时将整个文件镜像复制到交换空间，并从空间交换执行按页调度，那么有可能获得更好的性能。

另一种选择是开始时从文件系统进行按需调页，但置换出来的页写入交换空间，而后的调页则从交换空间中读取。这种方法确保只有需要的页才从文件系统中调入，又可以保证一定的性能。

## **写时复制**

**写时复制Copy-on-Write (COW) **运行父进程与子进程开始时共享同一页面，这些页面标记为写时复制页，即如果任何一个进程需要对页进行写操作，那就创建一个共享页的副本。

因为指标及那些能够被修改的页，所以创建进程的过程更有效率。

写时复制所需的空闲也老子一个空闲缓冲池，系统通常用**按需填零(zero-fill-on-demand)**的技术分配这些页。按需填零在需要分配之前先填零，因此清除了以前的内容。

下面的两个过程提箱了进程1修改C前后的物理内存的情况。 

**before**![这里写图片描述](http://img.blog.csdn.net/20151216173528107) 
**after** 
![这里写图片描述](http://img.blog.csdn.net/20151216173548548) 

如果没有空闲帧时该如何处理呢？

- 页替换：在内存中找到一些不再使用的页，将它换出去。
- 一些页可能被多次加载如内存。

## **页面置换**

操作系统为何要进行页面置换呢？这是由于操作系统给用户态的应用程序提供了一个虚拟的“大容量”内存空间，而实际的物理内存空间又没有那么大。所以操作系统就就“瞒着”应用程序，只把应用程序中“常用”的数据和代码放在物理内存中，而不常用的数据和代码放在了硬盘这样的存储介质上。如果应用程序访问的是“常用”的数据和代码，那么操作系统已经放置在内存中了，不会出现什么问题。但当应用程序访问它认为应该在内存中的的数据或代码时，如果这些数据或代码不在内存中，则根据上文的介绍，会产生缺页异常。这时，操作系统必须能够应对这种缺页异常，即尽快把应用程序当前需要的数据或代码放到内存中来，然后重新执行应用程序产生异常的访存指令。如果在把硬盘中对应的数据或代码调入内存前，操作系统发现物理内存已经没有空闲空间了，这时操作系统必须把它认为“不常用”的页换出到磁盘上去，以腾出内存空闲空间给应用程序所需的数据或代码。

操作系统迟早会碰到没有内存空闲空间而必须要置换出内存中某个“不常用”的页的情况。如何判断内存中哪些是“常用”的页，哪些是“不常用”的页，把“常用”的页保持在内存中，在物理内存空闲空间不够的情况下，把“不常用”的页置换到硬盘上就是页面置换算法着重考虑的问题。容易理解，一个好的页面置换算法会导致缺页异常次数少，也就意味着访问硬盘的次数也少，从而使得应用程序执行的效率就高。

下面提供了一种需要页置换的情况。

![这里写图片描述](http://img.blog.csdn.net/20151216174320494)

### **基本页置换**

基本页置换采用方法如下。

- 查找需要页在磁盘上的位置。

- 查找一空闲帧：

   

  ​

  - 如果有空闲帧，那么就使用它
  - 如果没有空闲帧，那么就是用页置换算法选择一个**“牺牲”帧（victim frame）**
  - 将牺牲帧的内容放到磁盘上，改变页表和帧表。

- 将所需页读入（新）空闲帧，改变页表和帧表。

- 重启用户进程。

![这里写图片描述](http://img.blog.csdn.net/20151216174829210)

页置换是按需调页的基础。为锁骨下班按需调页，必须解决两个主要问题：必须开发**帧分配算法(frame-allocation algorithm)**和**页置换算法(page-replacement algorithm)**。如果在内存中有多个进程，那么必须决定为每个进程各分配多少帧。而且，当需要页置换时，必须选择要置换的帧。

可以这样来评估一个算法：针对特定内存引用序列，运行某个置换算法，并计算出页错误的数量。内存的引用序列成为**引用串(reference string)**。

第一，对给定页大小（页大小通常由硬件或系统来决定），只需要考虑页码，而不需要完整的地址。第二，如果有一个页p的引用，那么任何紧跟着对页p的引用绝不会产生页错误。页p在第一次引用时已在内存中，任何紧跟着的引用绝不会出错。

页错误和帧数量图 
![这里写图片描述](http://img.blog.csdn.net/20151216175638269)

### **FIFO页置换**

该算法总是淘汰最先进入内存的页，即选择在内存中驻留时间最久的页予以淘汰。只需把一个应用程序在执行过程中已调入内存的页按先后次序链接成一个队列，队列头指向内存中驻留时间最久的页，队列尾指向最近被调入内存的页。这样需要淘汰页时，从队列头很容易查找到需要淘汰的页。FIFO算法只是在应用程序按线性顺序访问地址空间时效果才好，否则效率不高。因为那些常被访问的页，往往在内存中也停留得最久，结果它们因变“老”而不得不被置换出去。FIFO算法的另一个缺点是，它有一种异常现象（Belady现象），即在增加放置页的页帧的情况下，反而使缺页异常次数增多。

问题：随机一访问串和驻留集的大小，通过模拟程序显示淘汰的页号并统计命中率。示例：

输入访问串：7 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1

驻留集大小：3

![这里写图片描述](http://images2015.cnblogs.com/blog/764050/201509/764050-20150904162745903-615119421.png)

红色表示：指针指向调入内存的页面中“最老“的页面

通过模拟程序输出淘汰的页号分别为：7 0 1 2 3 0 4 2 3

命中率为：513

注意：内存的页面中“最老“的页面，会被新的网页直接覆盖，而不是“最老“的页面先出队，然后新的网页从队尾入队。

### **最优(Optimal)置换**

由Belady于1966年提出的一种理论上的算法。其所选择的被淘汰页面，将是以后永不使用的或许是在最长的未来时间内不再被访问的页面。采用最佳置换算法，通常可保证获得最低的缺页率。但由于操作系统其实无法预知一个应用程序在执行过程中访问到的若干页中，哪一个页是未来最长时间内不再被访问的，因而该算法是无法实际实现，但可以此算法作为上限来评价其它的页面置换算法。

### **LRU（Least Recently Used）页置换**

FIFO置换算法性能之所以较差，是因为它所依据的条件是各个页调入内存的时间，而页调入的先后顺序并不能反映页是否“常用”的使用情况。

最近最久未使用（LRU）置换算法，是根据页调入内存后的使用情况进行决策页是否“常用”。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU置换算法是选择最近最久未使用的页予以淘汰。该算法赋予每个页一个访问字段，用来记录一个页面自上次被访问以来所经历的时间t,，当须淘汰一个页面时，选择现有页面中其t值最大的，即最近最久未使用的页面予以淘汰。

问题：随机一访问串和驻留集的大小，通过模拟程序显示淘汰的页号并统计命中率。示例：

输入访问串：7 0 1 2 0 3 0 4 2 3 0 3 2

驻留集大小：3

算法的实现：由于LRU算法淘汰的是上次使用距离t时刻最远的页，故需记录这个距离。

有两张方法：

1. 计数器：为每个页表项关联一个使用时间域，并为CPU增加一个逻辑时钟或计数器。对每次内存引用，计数器都会增加。每次内存引用时，时钟寄存器的内容会复制到相应页所对应页表项的使用时间域内。置换具有最小时间的页，这种方案需要搜索页表以查找LRU页，且每次内存访问都要写入内存。在页表改变时也必须要保证时间，必须考虑时钟溢出。
2. 堆栈：实现LRU置换的另一个方法是采用页码堆栈。每当引用一个页，该页就从堆栈中删除并放在顶部，这样，堆栈底部总是LRU页，该堆栈可实现为具有头指针和尾指针的双向链表

每次内存引用都必须更新时钟域或堆栈，如果每次引用都采用中断，以允许软件更新这些数据结构，那么它会使内存引用慢至少10倍

![这里写图片描述](http://images2015.cnblogs.com/blog/764050/201509/764050-20150904162715513-1676240402.png)

红色表示：每个页帧对应的计数器值

通过模拟程序输出淘汰的页号分别为：7 1 2 3 0 4

命中率为：413

LRU的另一种通俗理解：

例如一个三道程序，等待进入的是1，2，3，4，4，2，5，6，3，4，2，1。先分别把1，2，3导入，然后导入4，置换的是1，因为他离导入时间最远。然后又是4，不需要置换，然后是2，也不需要，因为内存中有，到5的时候，因为3最远，所以置换3，依次类推。

注意：虽然两个算法都是用队列这种数据结构实现的，但具体操作不完全遵从队列的原则。这一点不必纠结。

命中率是指在队满的情况下，新的元素的加入，不影响队列其它元素。即该元素已存在在队列中。

OPT、LRU以及FIFO算法的对比图如下所示： 

![这里写图片描述](http://images2015.cnblogs.com/blog/764050/201509/764050-20150904163359872-179353147.png)

### **近似LRU页置换**

很少有计算机系统能够提供足够的硬件来支持真正的LRU页置换。有的系统不提供任何支持，因此必须使用其他置换算法。然而，许多系统都通过应用为方式提供一定支持，页表内的每项都关联着一个**引用位(reference bit)**，每当引用一个页时，相应页表的引用位就会被引脚置位。如添加一个8bit的引用位（极端情况下只有一个引用位，即二次机会算法）。每个时钟都向右移位，引用的话高位置1，否则置0。

开始，操作系统会将所有引用位都清零。随着用户进程的执行，与引用页相关联的引用位被硬件置位。通过检查引用位，能确定那些用过而那些没用过。这种部分排序信息导致了许多近似LRU算法的页置换算法。

- 附加引用位算法：

   

  ​

  - 可以为位于内存中的每个表中的页保留一个8bit的字节。操作系统把每个页的引用位转移到其8bit字节的高位，而将其他位右移，并抛弃最低位。如果将8bit字节作为无符号整数，那么具有最小值的页为LRU页，且可以被置换。

- 二次机会算法：

   

  ​

  - 二次机会置换的基本算法是FIFO置换算法。当要选择一个页时，检查其引用位。如果其值为0，那么就直接置换该页。如果引用位为1，那么就给该页第二次机会，并选择下一个FIFO页。当一个页获得第二次机会时，其引用位清零。且其到达时间设为当前时间。因此获得第二次机会的页，在所有其他页置换之前，是不会被置换的。另外，如果一个页经常使用以致于其引用位总是得到设置，那么它就不会被置换。
  - 一种实现二次机会算法的方法是采用循环队列。用一个指针表示下次要置换哪个页。当需要一个帧时，指针向前移动直到找到一个引用位为0的页。在向前移动时，它将清除引用位。

- 增强型二次机会算法

   

  ​

  - 通过将引用位和修改位作为一个有序对来考虑，能增强二次机会算法。有下面四种可能类型：

     

    ​

    - 1 (0,0)最近没有使用且也没有修改。—用于置换的最佳页
    - 2 (0,1)最近没有使用但修改过。—不是很好，因为在置换之前需要将页写出到磁盘
    - 3 (1,0)最近使用过但没有修改—它有可能很快又要被使用
    - 4 (1,1)最近使用过且修改过—它有可能很快又要被使用，且置换之前需要将页写出到磁盘

当页需要置换时，每个页都属于这四种类型之一。置换在最低非空类型中所碰到的页，可能要多次搜索整个循环队列。

### **基于计数的页置换**

有如下两种算法： 
\1. 最不经常使用页置换算法(LFU) 
\2. 最常使用页置换算法(MFU)

这两种算法的实现都很费时，且不能很好地近似OPT置换算法。

### **页缓冲算法**

系统通常保留一个空闲帧缓冲池。当出现页错误时，会像以前一样选择一个牺牲帧，在牺牲帧写出之前，所需要的页就从缓冲池中读到空闲内存。

## **帧分配**

如何在各个进程之间分配一定的空闲内存？ 
简单办法是将帧挂在空闲帧链表上，当发生页错误之时即进行分配。进程终止时帧再次放回空闲帧链表。 
帧分配策略受到多方面限制。例如， 分配数不能超过可用帧数，也必须分配至少最少数量。保证最少量的原因之一是性能。页错误增加会减慢进程的执行。并且，在指令完成前出现页错误，该指令必须重新执行。所以有足够的帧至关重要。 
每个进程帧的最少数量由体系结构决定，而最大数量是由可用物理内存数量决定。

### **分配算法**

1）平均分配，每个进程一样多 
2）按进程大小使用比例分 
3）按进程优先级分 
4）大小和优先级组合分

### **全局分配和局部分配**

全局置换允许进程从所有帧集合中选择一个进行置换，而不管该帧是否已分配给其他进程，即它可以从其他进程抢夺帧，比如高优先级抢夺低优先级的帧；局部分配则要求每个进程只能从自己的分配帧中分配。 
全局置换通常有更好的吞吐量，且更为常用